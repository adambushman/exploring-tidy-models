---
title: "Basic {tidymodels} example"
author: "Adam BUshman"
output: html_document
---

# Basic {tidymodels} examples

In my learning path of {tidymodels}, I'm creating this resource as a start guide for creating many of the core model types. They will be small, getting started examples that can be repurposed into grander projects.


## Setup

```{r}
#| echo: FALSE

library('tidyverse')
library('tidymodels')
library('broom')
```


## Linear Regression

Using the car prices data set from {modeldata}, wherein we'll look to model the price of a car models based on discrete and continuous variables like mileage, cylinders, body type, etc.

```{r}
data_lmr <- modeldata::car_prices
```

```{r}
lmr_mod <-
  linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

lmr_mod
```

We initially call the model we want to use. Then, we set the mode (only one choice for this model). Then, we set the engine (only one choice for this model).

```{r}
fit_lmr <-
  lmr_mod %>%
  fit(Price ~ ., data = data_lmr)

fit_lmr
```

With the model defined, we now "fit" (define which variables are independent and which are dependent). 

```{r}
fit_lmr %>%
  pluck("fit") %>%
  summary()
```

With the model fit to the data, we can inspect the summary easily enough by extracting it from the fit object.

```{r}
# Fit summary put in a tibble
fit_lmr %>% 
  tidy()

# Summary statistics put in a tibble
fit_lmr %>%
  glance()

# Appends the fitted and residual values to the original data
fit_lmr %>%
  pluck("fit") %>%
  augment()
```

We should now tidy up the output for easier use in plotting and table generation.

```{r}
new_data <- tibble(
  Mileage = c(23000,7000), 
  Cylinder = c(4, 4), 
  Doors = c(4, 4), 
  Cruise = c(1, 1), 
  Sound = c(1,1), 
  Leather = c(0, 1), 
  Buick = c(0, 0), 
  Cadillac = c(0, 0), 
  Chevy = c(1, 0), 
  Pontiac = c(0, 0), 
  Saab = c(0, 0), 
  Saturn = c(0, 0), 
  convertible = c(0, 0), 
  coupe = c(0, 0), 
  hatchback = c(0, 1), 
  sedan = c(1, 0), 
  wagon = c(0, 0)
)

```

```{r}
predict(fit_lmr, new_data = new_data)

predict(
  fit_lmr, new_data = new_data, 
  type = "pred_int", 
  level = 0.9
)
```

We now predict some values with new data!


## Decision Trees

### Regression

```{r}
data_dtr <- modeldata::concrete
```

```{r}
dtr_mod <-
  decision_tree() %>%
  set_mode("regression") %>%
  set_engine("rpart")

dtr_mod
```
The model to use is a decision tree, mode ebeing regression, and the engine being rpart.

```{r}
fit_dtr <-
  dtr_mod %>%
  fit(compressive_strength ~ ., data = data_dtr)

fit_dtr
```


```{r}
# Visualizes the variable importance level of each feature
vip::vip(fit_dtr$fit)
```

Let's fit the model to the data!

```{r}
new_data <- tibble(
  cement = c(240.0, 600.0), 
  blast_furnace_slag = c(5.0, 12.0), 
  fly_ash = c(0.0, 0.0), 
  water = c(192, 162), 
  superplasticizer = c(2.5, 0.0), 
  coarse_aggregate = c(921.0, 1061.0), 
  fine_aggregate = c(621.0, 331.0), 
  age = c(90, 200)
)
```


```{r}
predict(fit_dtr, new_data = new_data)
```

Let's assess the model now with new data!

### Classification

```{r}
data_dtc <- modeldata::penguins %>% filter(!is.na(bill_length_mm))

split_data <- rsample::initial_split(data_dtc)

train_set <- rsample::training(split_data)
test_set <- rsample::testing(split_data)
```

```{r}
dtc_mod <-
  decision_tree(tree_depth = 3) %>%
  set_mode("classification") %>%
  set_engine("rpart")

dtc_mod
```
The model to use is a decision tree, mode being classification, and the engine being rpart.

```{r}
fit_dtc <-
  dtc_mod %>%
  fit(species ~ ., data = train_set)

fit_dtc
```

```{r}
# Visualizes the variable importance level of each feature
vip::vip(fit_dtc$fit)
```

```{r}
predictions <- predict(fit_dtc, test_set)
results <- tibble(predicted = predictions$.pred_class, observed = test_set$species)
```

Looking at the results.

```{r}
results %>%
  yardstick::metrics(truth = observed, estimate = predicted)
```

### Tuning a tree

```{r}
data_dtt <- modeldata::credit_data

split_data <- rsample::initial_split(data_dtt)

train_set <- rsample::training(split_data)
test_set <- rsample::testing(split_data)
```

```{r}
dtt_mod <-
  decision_tree(tree_depth = tune()) %>%
  set_mode("classification") %>%
  set_engine("rpart")
```

```{r}
# Define a recipe (the steps)
dtt_recipe <- recipe(Status ~ ., data = train_set)

# Create a workflow (the things to do over and over again)
dtt_workflow <- workflow() %>%
  add_model(dtt_mod) %>%
  add_recipe(dtt_recipe)

# Specify a grid (where to list the results)
dtt_grid <- expand.grid(tree_depth = seq(1,10))

# Specify the tuning (how to run the workflow)
dtt_tune <- tune_grid(
  dtt_workflow, 
  resamples = rsample::bootstraps(train_set, times = 5), 
  grid = dtt_grid, 
  metrics = metric_set(accuracy)
)
```

```{r}
results <- 
  dtt_tune %>%
  unnest(.metrics)


ggplot(results, aes(x = tree_depth, y = .estimate)) +
  geom_point() +
  stat_smooth() +
  scale_x_discrete()
```
